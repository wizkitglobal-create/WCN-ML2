import dash
from dash import dcc, html, dash_table, Input, Output, State
import dash_bootstrap_components as dbc
import plotly.graph_objs as go
from PIL import Image, ImageDraw, ImageFont
import base64
import io
from roboflow import Roboflow
import pandas as pd
from datetime import datetime
import boto3
from botocore.exceptions import NoCredentialsError
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from PIL import Image, ImageDraw, ImageFont
from exif import Image as ExifImage
import numpy as np



# Initialize Roboflow model
rf = Roboflow(api_key="4mk8lPHkiCrauugzg3jb")
project = rf.workspace().project("ml2-wcn-ukm")
model = project.version(16).model

dynamodb = boto3.resource('dynamodb',
    region_name='ap-southeast-1'
)
aggregate_table = dynamodb.Table('AggregateData')
records_table = dynamodb.Table('Records')

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.CYBORG], suppress_callback_exceptions=True)

scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']
creds = ServiceAccountCredentials.from_json_keyfile_name('ml2-open-dataset-92e685aebdd6.json', scope)
client = gspread.authorize(creds)
sheet = client.open("ML2 Open-Source Dataset").sheet1

def resize_image(image, resize_factor=0.75):
    new_size = (int(image.size[0] * resize_factor), int(image.size[1] * resize_factor))
    return image.resize(new_size, Image.ANTIALIAS)
def convert_image_to_np_array(contents, resize_factor=0.75):
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    image = Image.open(io.BytesIO(decoded))

    # Resize image
    image = resize_image(image, resize_factor)

    return np.array(image)
def decimal_coords(coords, ref):
    decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600
    if ref == "S" or ref == "W":
        decimal_degrees = -decimal_degrees
    return decimal_degrees

def get_image_coordinates(image_bytes):
    image_bytes.seek(0)  # Make sure we're at the start of the BytesIO object
    img = ExifImage(image_bytes)

    if img.has_exif:
        try:
            lat = decimal_coords(img.gps_latitude, img.gps_latitude_ref)
            lon = decimal_coords(img.gps_longitude, img.gps_longitude_ref)
            return lat, lon
        except AttributeError:
            print('No Coordinates Found.')
            return None, None
    else:
        print('The Image has no EXIF information')
        return None, None

def upload_to_s3(image_bytes_io, bucket, s3_file):
    s3 = boto3.client('s3', region_name='ap-southeast-1')

    try:
        # Use 'upload_fileobj' method to upload an in-memory file-like object
        s3.upload_fileobj(image_bytes_io, bucket, s3_file)
        print("Upload Successful")
        return True

    except NoCredentialsError:
        print("Credentials not available")
        return False
    except Exception as e:
        print("An unexpected error occurred:", e)  # added this line to catch all other exceptions
        return False
def parse_contents(contents, prediction):
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    image = Image.open(io.BytesIO(decoded))

    draw = ImageDraw.Draw(image)
    font = ImageFont.load_default()

    for obj in prediction['predictions']:
        x1, y1, x2, y2 = obj['x'], obj['y'], obj['x'] + obj['width'], obj['y'] + obj['height']
        label = obj['class']

        text_width, text_height = draw.textsize(label, font=font)
        draw.rectangle([x1, y1, x2, y2], outline="red", width=3)
        draw.rectangle([x1, y1 - text_height - 4, x1 + text_width + 4, y1], fill="red")
        draw.text((x1 + 2, y1 - text_height - 2), label, fill="white", font=font)

    buffered = io.BytesIO()
    image.save(buffered, format="JPEG")
    encoded_image = base64.b64encode(buffered.getvalue()).decode()
    src = f"data:image/jpeg;base64,{encoded_image}"

    return html.Img(src=src, style={'maxWidth': '100%', 'height': 'auto'})

def get_initial_aggregate_data():
    response = aggregate_table.scan()
    aggregate_data = {item['label']: item['count'] for item in response['Items']}
    return aggregate_data

def convert_image_to_pil(contents):
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    image = Image.open(io.BytesIO(decoded))
    return image

def upload_to_dynamodb(counter, lon, lat, classes_string):
    try:
        records_table.put_item(
            Item={
                'id': str(counter),
                'datetime': datetime.now().isoformat(),
                'lon': str(lon),
                'lat': str(lat),
                'classes': classes_string,
                'image_url': f'image_{counter}.jpg',
            })
        print("Uploaded data to DynamoDB")
        return True
    except Exception as e:
        print("Couldn't upload data to DynamoDB: ", e)
        return False

upload_card = dbc.Card(
    [
        dbc.CardBody(
            [
                html.H4('Upload Image', className='card-title'),
                dcc.Upload(
                    id='upload-image',
                    children=html.Div([
                        'Drag and Drop or ',
                        html.A('Select Files')
                    ]),
                    style={
                        'width': '100%',
                        'height': '60px',
                        'lineHeight': '60px',
                        'borderWidth': '1px',
                        'borderStyle': 'dashed',
                        'borderRadius': '5px',
                        'textAlign': 'center',
                        'margin': '10px'
                    },
                ),
                html.Div(id='output-image-upload')
            ]
        ),
    ], style={'margin': '10px'}
)

bar_chart_card = dbc.Card(
    [
        dbc.CardBody(
            [
                html.H4('Inference Results', className='card-title'),
                dcc.Graph(id='inference-graph', config={'displayModeBar': False}),
            ]
        ),
    ], style={'margin': '10px'}
)

bubble_map_card = dbc.Card(
    [
        dbc.CardBody(
            [
                html.H4('Bubble Map', className='card-title'),
                dcc.Graph(id='bubble-map', config={'displayModeBar': False}),
            ]
        ),
    ], style={'margin': '10px'}
)

data = {' ': ['Total Images Uploaded', 'Total Inferences Made'],}
df = pd.DataFrame(data)

table_card = dbc.Card(
    [
        dbc.CardBody(
            [
                html.H4('Table', className='card-title'),
                dash_table.DataTable(id='table',columns=[{'name': i, 'id': i} for i in df.columns], data=df.to_dict('records'))
            ]
        )
    ]
)

app.layout = html.Div(
    [
        html.Div('Machine Learning for Mitigating Litter',
                 style={'backgroundColor': '#FD7E14', 'color': 'white', 'fontSize': 24, 'padding': 10, 'textAlign': 'center'}),
        dcc.Store(id='aggregate-data', data=dict()),  # Add this line to include data storage in the layout
        dbc.Row([dbc.Col(upload_card, width=12, md=6, style={"padding": "10px"}),
                 dbc.Col(bar_chart_card, width=12, md=6, style={"padding": "10px"})]),
        dbc.Row([dbc.Col(bubble_map_card, width=12, md=6, style={"padding": "10px"}),
                 dbc.Col(table_card, width=12, md=6, style={"padding": "10px"})]),
        dcc.Interval(
            id='interval-component',
            interval=5 * 1000,  # in milliseconds
            n_intervals=0
        )
    ], style={'backgroundColor':'#0F0F0F', 'padding':'10px'}
)
def get_file_counter():
    try:
        with open('counter.txt', 'r') as f:
            count = int(f.read().strip())
    except (FileNotFoundError, ValueError):
        count = 1
    with open('counter.txt', 'w') as f:
        f.write(str(count + 1))
    return count

def store_aggregate_data_in_dynamodb(aggregate_data):
    with aggregate_table.batch_writer() as batch:
        for label, count in aggregate_data.items():
            batch.put_item(Item={'label': label, 'count': count})

def fetch_coordinates():
    response = records_table.scan()
    data = [(float(item['lon']), float(item['lat'])) for item in response['Items'] if item['lon'] != 'None' and item['lat'] != 'None']
    return data


@app.callback(
    Output('output-image-upload', 'children'),
    Output('inference-graph', 'figure'),
    Output('aggregate-data', 'data'),
    Input('upload-image', 'contents'),
    State('aggregate-data', 'data'),
    prevent_initial_call=True
)



def update_output(contents, aggregate_data):
    if contents is None:
        raise dash.exceptions.PreventUpdate
    aggregate_data = get_initial_aggregate_data()
    # Save to a BytesIO object to use with model.predict
    image = convert_image_to_pil(contents)
    image_byte_arr = io.BytesIO()
    image.save(image_byte_arr, format="JPEG", exif=image.info["exif"])
    counter = get_file_counter()
    # Read EXIF data
    image_exif_io = image_byte_arr.getvalue()
    image_exif_io = io.BytesIO(image_exif_io)
    lat, lon = get_image_coordinates(image_exif_io)

    # Resize image and convert image to numpy array
    image_array = convert_image_to_np_array(contents)

    prediction = model.predict(image_array, confidence=10, overlap=30).json()

    children = parse_contents(contents, prediction)

    if aggregate_data is None:
        aggregate_data = {}


    classes = []
    for obj in prediction['predictions']:
        cls = str(obj['class'])
        classes.append(cls)
        aggregate_data[cls] = aggregate_data.get(cls, 0) + 1     # Update aggregate data for each class

    # Prepare class list string for sheet insertion outside of loop
    classes_string = ', '.join((set(classes)))
    # Insert a new row in the google sheet only once for each image
    records_table.put_item(
        Item={
            'id': str(counter),
            'datetime': datetime.now().isoformat(),
            'lon': str(lon),
            'lat': str(lat),
            'classes': classes_string,
            'image_url': f'image_{counter}.jpg',
        }
    )

    bar_graph = go.Figure(data=[go.Bar(x=list(aggregate_data.keys()), y=list(aggregate_data.values()))])

    bar_graph = go.Figure(data=[
        go.Bar(
            x=list(aggregate_data.keys()),
            y=list(aggregate_data.values()),
            marker_color='rgb(55, 83, 109)'    # change the bar color
        )
    ])
    bar_graph.update_layout(
        title_text='Inference Results',
        title_x=0.5,
        paper_bgcolor='rgb(248, 248, 255)',
        plot_bgcolor='rgb(248, 248, 255)',
        hovermode='x',
        autosize=True,
        bargap=0.2,
        xaxis=dict(
            title='Labels',
            titlefont=dict(
                size=14,
                color='black'
            ),
            showticklabels=True,
            tickangle=0,
            tickfont=dict(
                size=12,
                color='black'
            )
        ),
        yaxis=dict(
            title='Count',
            titlefont=dict(
                size=14,
                color='black',
            ),
            showgrid=False,
            gridcolor='rgb(183,183,183)',
        ),
    )

    image_byte_arr.seek(0)  # Ensure BytesIO object is at the start
    uploaded = upload_to_dynamodb(counter, lon, lat, classes_string)
    if not uploaded:
        print("Failed to upload data to DynamoDB")

    if uploaded:
        print("Image has been uploaded to S3")
    else:
        print("Image upload to S3 failed")

    store_aggregate_data_in_dynamodb(aggregate_data)

    return children, bar_graph, aggregate_data

@app.callback(
    Output('bubble-map', 'figure'),
    Input('interval-component', 'n_intervals'),
    prevent_initial_call=True
)
def update_bubble_map(_):
    coords = fetch_coordinates()
    lons = [coord[0] for coord in coords]
    lats = [coord[1] for coord in coords]

    bubble_map = go.Figure(
        data=go.Scattergeo(
            lon=lons,
            lat=lats,
            mode='markers',
            marker=dict(
                size=8,
                opacity=0.8,
                reversescale=True,
                autocolorscale=False,
                symbol='circle',
                line=dict(
                    width=1,
                    color='rgba(102, 102, 102)'
                ),
                colorscale='Viridis',
            )
        )
    )

    bubble_map.update_layout(
        title_text='Bubble Map',
        geo={
            'showframe': False,
            'showcoastlines': False,
            'projection_type': 'natural earth'
        }
    )

    return bubble_map

if __name__ == "__main__":
    app.run_server(debug=True)

#working google sheet
#working bucket
#naming convention changed

#update the table working!!
#dynamoDB handling working YESSS!

#want to update the map
